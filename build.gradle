apply plugin: 'java'
apply plugin: 'scala'

version = '1.0'

if (!hasProperty('against')) {
    ext.against = 'maven'    // default
}

ext.Home = System.env.HOME
ext.DseHome = System.env.DSE_HOME ?: "$Home/dse"
ext.DseResources = System.env.DSE_RESOURCES ?: "$Home/dse/resources/"
ext.mainClassName = "com.datastax.sparkstress.SparkCassandraStress"

def determineConnectorVersion() {
    if (against == 'dse') {
        def connector = fileTree(dir: "$DseResources/spark/lib", include: '*connector_*.jar')
        def connectorJarName = (connector as List)[0].name
        def match = connectorJarName =~ /connector_.*-(\d+\.\d+.\d+).*\.jar/
        assert match.find(), "Unable to find Spark Cassandra Connector"
        assert match.group(1).length() != 0, "Unable to determine version from " + match.group(0)
        println("Connector Version = " + match.group(1))
        return match.group(1)
    }
    if (against == 'maven') {
        return System.env.CONNECTOR_VERSION ?: '1.4.0-M3'
    }
}

// Parameters for buliding against Maven Libs
def ConnectorVersion = determineConnectorVersion()
def SparkVersion = System.env.SPARK_VERSION ?: '1.4.1'

// Parameter for building against Connector Repository
def SparkCCHome = System.env.SPARKCC_HOME ?:
        "$Home/repos/spark-cassandra-connector/"



def deps = [
        dse   : {
            println "Using DSE libraries"
            [
                    'dse/lib',
                    'driver/lib',
                    'cassandra/lib',
                    'spark/lib',
                    'shark/lib',
                    'hadoop',
                    'hadoop/lib',
            ].each { dir ->

                provided fileTree(dir: "$DseResources/$dir", include: '*.jar')
            }

            [
                    '/build',
                    '/lib',
                    '/build/lib'
            ].each { dir ->
                provided fileTree(dir: "$DseHome/$dir", include: '*.jar')
            }


        },
        maven : {
            println "Using Maven Libraries"
            compile "com.datastax.spark:spark-cassandra-connector_2.10:$ConnectorVersion"
            provided "org.apache.spark:spark-core_2.10:$SparkVersion"
            provided "org.apache.spark:spark-streaming_2.10:$SparkVersion"
        },
        source: {
            println "Using Assembly Jar from Source Repo"

            compile fileTree(dir: "$SparkCCHome/spark-cassandra-connector/target/scala-2.10/", include: "*.jar")
            provided "org.apache.spark:spark-core_2.10:$SparkVersion"
            provided "org.apache.spark:spark-streaming_2.10:$SparkVersion"
        },

]

task build_connector(type: Exec) {
    workingDir SparkCCHome
    commandLine 'sbt/sbt', 'clean'
    commandLine 'sbt/sbt', 'assembly'
}

if (against == 'source') {
    jar.dependsOn build_connector
}


jar {
    manifest.attributes("Main-Class": mainClassName)
    baseName = "SparkCassandraStress"
    from {
        (configurations.runtime - configurations.provided).collect {
            it.isDirectory() ? it : zipTree(it)
        }
    } {
        exclude "META-INF/*.SF"
        exclude "META-INF/*.DSA"
        exclude "META-INF/*.RSA"
    }
}

configurations {
    provided
    compile.extendsFrom provided
}

ext {
    scalaVersion = '2.10.5'
}

repositories {
    mavenCentral()
}

test {
    if(against == 'dse') {
        exclude '**/NonDseWriteTaskTests/**'
    }
    testLogging {
        events "passed", "skipped", "failed", "standardOut", "standardError"
    }
}

dependencies {
    testCompile "org.scala-lang:scala-library:2.10.5"
    testCompile "com.datastax.spark:spark-cassandra-connector-embedded_2.10:1.2.1"
    testCompile "org.scalatest:scalatest_2.10:2.2.4"
    compile "com.github.scopt:scopt_2.10:3.2.0"
    compile "joda-time:joda-time:2.8.1"

    println "Checking dependency flag: $against"

}

dependencies deps[(against)]

sourceSets {
    main {
        scala {
            srcDirs = ['src/main/scala']
            if (against == 'dse') {
                srcDirs += 'src/dse'
            } else {
                srcDirs += 'src/apache'
            }

            //Api Change Catcher -- This is done to catch the CassandraCount Change in connector 1.2.4
            println(ConnectorVersion)
            def (major, minor, patch) = ConnectorVersion.split(/\./,3).collect { (it.find(/^\d+/).toInteger()) }
            if (major == 1 && minor == 2 && patch < 4){
                println("using special 1.2.0 -1.2.3 stubs")
                srcDirs += 'src/connector/1.2.0to1.2.3'
            } else if (major <= 1 && minor <= 1 ) {
                println("using pre-Connector 1.2.0 stubs")
                srcDirs += 'src/connector/lessThan1.2.0'
            } else { srcDirs += 'src/connector/default' }

        }
    }
}
